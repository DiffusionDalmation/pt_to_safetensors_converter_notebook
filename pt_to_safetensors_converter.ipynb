{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOHKR3fUcOgav4VTZNYm8O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiffusionDalmation/pt_to_safetensors_converter_notebook/blob/main/pt_to_safetensors_converter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Mount Google Drive\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "import os\n",
        "\n",
        "def inf(msg, style, wdth): inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth));display(inf)\n",
        "Shared_Drive = \"\" #@param {type:\"string\"}\n",
        "#@markdown - If you're not using a shared drive, leave this empty\n",
        "\n",
        "print(\"\u001b[0;33mConnecting...\")\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "if Shared_Drive!=\"\" and os.path.exists(\"/content/gdrive/Shareddrives\"):\n",
        "  mainpth=\"Shareddrives/\"+Shared_Drive \n",
        "else:\n",
        "  mainpth=\"MyDrive\"\n",
        "\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')"
      ],
      "metadata": {
        "id": "fCR2boKCTx0z",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Required Dependencies\n",
        "!pip install torch\n",
        "!pip install safetensors"
      ],
      "metadata": {
        "id": "5S88gkUJzeqG",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inf(msg, style, wdth): inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth));display(inf)\n",
        "file_path = \"\" #@param {type:\"string\"}\n",
        "#@markdown - Copy and paste the path to a pickle file that you are converting, or a directory containing several pickle files\n",
        "#@markdown - For example: /content/gdrive/MyDrive/myembedding.pt or /content/gdrive/MyDrive/my_directory\n",
        "#@markdown - Pickle files must be in .pt format\n",
        "verbose = True #@param {type:\"boolean\"}\n",
        "#@markdown - Check this box to get additional information about the pickle file you're converting"
      ],
      "metadata": {
        "id": "7aLFC6c4O5EW",
        "cellView": "form"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define Converter Functions\n",
        "import os\n",
        "from typing import Any, Dict\n",
        "\n",
        "import torch\n",
        "from safetensors.torch import save_file\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def process_pt_files(path: str, model_type: str, verbose=True) -> None:\n",
        "    if os.path.isdir(path):\n",
        "        # Path is a directory, process all .pt files in the directory\n",
        "        for file_name in os.listdir(path):\n",
        "            if file_name.endswith('.pt'):\n",
        "                process_file(os.path.join(path, file_name), model_type, verbose)\n",
        "    elif os.path.isfile(path) and path.endswith('.pt'):\n",
        "        # Path is a .pt file, process this file\n",
        "        process_file(path, model_type, verbose)\n",
        "    else:\n",
        "        print(f\"{path} is not a valid directory or .pt file.\")\n",
        "\n",
        "def process_file(file_path: str, model_type: str, verbose: bool) -> None:\n",
        "    # Load the PyTorch model\n",
        "    model = torch.load(file_path, map_location=device)\n",
        "\n",
        "    if verbose:\n",
        "      print(file_path)\n",
        "\n",
        "    if model_type == 'embedding':\n",
        "        s_model = process_embedding_file(model, verbose)\n",
        "    elif model_type == 'vae':\n",
        "        s_model = process_vae_file(model, verbose)\n",
        "    else:\n",
        "        raise Exception(f\"model_type `{model_type}` is not supported!\")\n",
        "\n",
        "    # Save the model with the new extension\n",
        "    if file_path.endswith('.pt'):\n",
        "        new_file_path = file_path[:-3] + '.safetensors'\n",
        "    else:\n",
        "        new_file_path = file_path + '.safetensors'\n",
        "    save_file(s_model, new_file_path)\n",
        "\n",
        "def process_embedding_file(model: Dict[str, Any], verbose: bool) -> Dict[str, torch.Tensor]:\n",
        "    # Extract the embedding tensors\n",
        "    model_tensors = model.get('string_to_param').get('*')\n",
        "    s_model = {\n",
        "          'emb_params': model_tensors\n",
        "            }\n",
        "\n",
        "    if verbose:\n",
        "        # Print the requested training information, if it exists\n",
        "        if ('sd_checkpoint_name' in model) and (model['sd_checkpoint_name'] is not None):\n",
        "            print(f\"Trained on {model['sd_checkpoint_name']}.\")\n",
        "        else:\n",
        "            print(\"Checkpoint name not found in the model.\")\n",
        "\n",
        "        if ('step' in model) and (model['step'] is not None):\n",
        "            print(f\"Trained for {model['step']} steps.\")\n",
        "        else:\n",
        "            print(\"Step not found in the model.\")\n",
        "        # Display the tensor's shape\n",
        "        print(f\"Dimensions of embedding tensor: {model_tensors.shape}\")\n",
        "        print()\n",
        "\n",
        "    return s_model\n",
        "\n",
        "def process_vae_file(model: Dict[str, Any], verbose: bool) -> Dict[str, torch.Tensor]:\n",
        "    # Extract the state dictionary\n",
        "    s_model = model[\"state_dict\"]\n",
        "    if verbose:\n",
        "        # Print the requested training information, if it exists\n",
        "        step = model.get('step', model.get('global_step'))\n",
        "        if step is not None:\n",
        "            print(f\"Trained for {step} steps.\")\n",
        "        else:\n",
        "            print(\"Step not found in the model.\")\n",
        "        print()\n",
        "    return s_model"
      ],
      "metadata": {
        "id": "UwH1lXmGw9XP",
        "cellView": "form"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert the pickle file(s)\n",
        "\n",
        "Execute the respective code block according to the type of pickle files you are converting.\n",
        "\n",
        "The converted Safetensors will be saved in the same directory as the original."
      ],
      "metadata": {
        "id": "LqEl4sM0sMPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Convert the Embedding(s)\n",
        "process_pt_files(file_path, 'embedding', verbose=verbose)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4LEWGfjiUeG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Convert the VAE(s)\n",
        "process_pt_files(file_path, 'vae', verbose=verbose)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Jil7A1ckyiHA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
